#!/usr/bin/env python3
"""
é›†æˆAPIçš„è§†é¢‘å­—å¹•ç”Ÿæˆ
ç›´æ¥æ›¿æ¢åŸæœ‰çš„caption.pyä¸­çš„segment_captionå‡½æ•°
"""

import os
import glob
import torch
import numpy as np
from PIL import Image
from tqdm import tqdm
from moviepy.video.io.VideoFileClip import VideoFileClip

def load_character_references(face_db_path):
    """Load character reference images and names from the face database"""
    character_references = []
    
    # Get all character folders
    character_folders = glob.glob(os.path.join(face_db_path, "*"))
    
    for folder in character_folders:
        character_name = os.path.basename(folder)
        # Get first image from the character folder
        image_files = glob.glob(os.path.join(folder, "*.[jp][pn][g]"))
        
        if image_files:
            # Load the first image as a reference
            ref_image = Image.open(image_files[0]).convert("RGB")
            # Add character reference with name
            character_references.append({
                "name": character_name,
                "image": ref_image
            })
    
    return character_references

def encode_video(video, frame_times):
    """Extract frames from video at specified times"""
    frames = []
    for t in frame_times:
        frames.append(video.get_frame(t))
    frames = np.stack(frames, axis=0)
    frames = [Image.fromarray(v.astype('uint8')).resize((1280, 720)) for v in frames]
    return frames

def segment_caption(video_name, video_path, segment_index2name, transcripts, 
                   segment_times_info, caption_result, error_queue):
    """
    API-based video captioning function to replace MiniCPM
    è¿™ä¸ªå‡½æ•°å¯ä»¥ç›´æ¥æ›¿æ¢åŸæœ‰çš„segment_captionå‡½æ•°
    """
    try:
        # å¯¼å…¥APIå¤„ç†å™¨
        import sys
        sys.path.append(os.path.join(os.getcwd(), '..', '..'))
        from api_video_processor import APIVideoProcessor
        
        # åˆå§‹åŒ–APIå¤„ç†å™¨ï¼ˆä¼šè‡ªåŠ¨ä»é…ç½®æ–‡ä»¶è¯»å–APIä¿¡æ¯ï¼‰
        processor = APIVideoProcessor(provider="openai")
        
        # Load character references from face_db
        current_dir = os.getcwd()
        face_db_path = os.path.join(current_dir, 'dataset/video_edit/face_db')
        character_references = load_character_references(face_db_path)
        
        print(f"ğŸ¬ ä½¿ç”¨GPT-4o APIè¿›è¡Œè§†é¢‘å­—å¹•ç”Ÿæˆ")
        print(f"ğŸ“ å¤„ç† {len(segment_index2name)} ä¸ªè§†é¢‘ç‰‡æ®µ")
        
        with VideoFileClip(video_path) as video:
            for index in tqdm(segment_index2name, desc=f"Captioning Video {video_name}"):
                frame_times = segment_times_info[index]["frame_times"]
                video_frames = encode_video(video, frame_times)
                segment_transcript = transcripts[index]
                
                # å‡†å¤‡è§’è‰²å‚è€ƒä¿¡æ¯
                char_refs = []
                for char_ref in character_references:
                    char_refs.append({
                        "name": char_ref["name"],
                        "image": char_ref["image"]
                    })
                
                # ä½¿ç”¨APIè¿›è¡Œè§†é¢‘å­—å¹•ç”Ÿæˆ
                try:
                    segment_caption = processor.video_captioning(
                        frames=video_frames,
                        character_refs=char_refs,
                        transcript=segment_transcript,
                        video_name=video_name
                    )
                    
                    # æ¸…ç†ç»“æœ
                    segment_caption = segment_caption.replace("\n", "").replace("<|endoftext|>", "")
                    caption_result[index] = segment_caption
                    
                    print(f"âœ… ç‰‡æ®µ {index} å­—å¹•ç”Ÿæˆå®Œæˆ: {segment_caption[:50]}...")
                    
                except Exception as e:
                    print(f"âŒ å¤„ç†ç‰‡æ®µ {index} å¤±è´¥: {e}")
                    # ä½¿ç”¨fallbackæè¿°
                    caption_result[index] = f"Video segment {index} showing {segment_transcript[:50]}..."
                
    except Exception as e:
        error_queue.put(f"Error in segment_caption:\n {str(e)}")
        raise RuntimeError

def merge_segment_information(segment_index2name, segment_times_info, transcripts, captions):
    """Merge segment information for storage"""
    inserting_segments = {}
    for index in segment_index2name:
        inserting_segments[index] = {"content": None, "time": None}
        segment_name = segment_index2name[index]
        inserting_segments[index]["time"] = '-'.join(segment_name.split('-')[-2:])
        inserting_segments[index]["content"] = f"Caption:\n{captions[index]}" 
        inserting_segments[index]["transcript"] = transcripts[index]
        inserting_segments[index]["frame_times"] = segment_times_info[index]["frame_times"].tolist()
    
    return inserting_segments

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    print("ğŸ¬ APIé›†æˆçš„è§†é¢‘å­—å¹•ç”Ÿæˆæ¨¡å—")
    print("ğŸ’¡ è¿™ä¸ªæ¨¡å—å¯ä»¥ç›´æ¥æ›¿æ¢åŸæœ‰çš„caption.py")
    print("ğŸ”§ ç¡®ä¿é…ç½®æ–‡ä»¶ä¸­çš„APIå¯†é’¥å’Œbase_urlæ­£ç¡®è®¾ç½®")
